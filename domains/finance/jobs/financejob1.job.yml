# The code below will be exported from the job definition without parameterization eg. /Workspace/Users/hussain.vahanvaty@databricks.com/Accounts/FY26/Turner/dabs-workshop/domains/ops
# Ensure that the relevant resources (notebook_path, warehouse_id) etc. are parameterized for each environment
resources:
  jobs:
    hv_finance_job1:
      name: hv-finance-job1
      description: Basic job tying together a notebook, python script and SQL query
      tasks:
        - task_key: notebook1
          notebook_task:
            notebook_path: "../notebooks/notebook1.py"
            source: WORKSPACE
        - task_key: python1
          depends_on:
            - task_key: notebook1
          spark_python_task:
            python_file: "../utils/script1.py"
          environment_key: Default
        - task_key: sql1
          depends_on:
            - task_key: python1
          sql_task:
            file:
              path: "../views/orm/query1.sql"
              source: WORKSPACE
            warehouse_id: 8baced1ff014912d # Note: parameterized from databricks.yml did NOT work here
      queue:
        enabled: true
      environments:
        - environment_key: Default
          spec:
            environment_version: "4"
      performance_target: PERFORMANCE_OPTIMIZED
